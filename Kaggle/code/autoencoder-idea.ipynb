{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport glob\nimport PIL.Image as Image\nimport torch.utils.data as data\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom tqdm import tqdm\nfrom ipywidgets import interact, fixed\n\nPREFIX = '/kaggle/input/vesuvius-challenge-ink-detection/train/1/'\nBUFFER = 30  # Buffer size in x and y direction\nZ_START = 27 # First slice in the z direction to use\nZ_DIM = 10   # Number of slices in the z direction\nTRAINING_STEPS = 30000\nLEARNING_RATE = 0.03\nBATCH_SIZE = 32\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nplt.imshow(Image.open(PREFIX+\"ir.png\"), cmap=\"gray\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numba\nimport numpy as np\nfrom PIL import Image\nimport torch\nfrom matplotlib import pyplot as plt\nfrom torch.utils.data import Dataset\nfrom typing import Tuple, List\nfrom torchvision.transforms import transforms\n\nclass VesuviusTrainData(Dataset):\n    _relative_sv_dir = \"surface_volume\"  # relative to the directory of train data\n\n    def __init__(self,\n                 dir_path: str = \"train/1\",\n                 z_start: int = 0,\n                 z_end: int = 64,\n                 nucleus_shape: Tuple[int, int] = (16, 16),\n                 hull_size: Tuple[int, int] = (64, 64),\n                 compress_depth =  None,\n                 give_indx = False\n                 ):\n        self.dir_path = dir_path\n\n        self.z_start = z_start\n        self.z_end = z_end\n\n        self.nucleus_shape = nucleus_shape\n        self.hull_size = hull_size\n        \n        self.compress_depth = compress_depth\n        self.give_indx = give_indx\n        \n        self._setup()\n\n    def __len__(self):\n        return len(self.indices)\n\n    def __getitem__(self, index: int):\n        i, j = self._get_pixel_from_index(self.indices[index])\n        nucleus_height, nucleus_width = self.nucleus_shape\n\n        if self.give_indx == False:\n            return (torch.from_numpy(\n                    self.images[\n                    :,\n                    i - self._left_hull + self._left_pad_image:\n                    i + nucleus_width + self._right_hull + self._left_pad_image,\n                    j - self._top_hull + self._top_pad_image:\n                    j + nucleus_height + self._bottom_hull + self._top_pad_image\n                     ]),\n                    torch.from_numpy(\n                    self.inklabels[i: i + nucleus_width,\n                    j: j + nucleus_height]))\n        else:\n            return (torch.from_numpy(\n                self.images[\n                :,\n                i - self._left_hull + self._left_pad_image:\n                i + nucleus_width + self._right_hull + self._left_pad_image,\n                j - self._top_hull + self._top_pad_image:\n                j + nucleus_height + self._bottom_hull + self._top_pad_image\n                 ]),\n                torch.from_numpy(\n                self.inklabels[i: i + nucleus_width,\n                               j: j + nucleus_height]),\n                   np.stack(([i+k for k in range(nucleus_width)],[\n                    j+k for k in range(nucleus_height)]),axis=1))\n\n    def _load_images(self, z_start=None,z_end=None):\n        if z_end is None:\n            z_end = self.z_end \n        if z_start is None:\n            z_start = self.z_start\n            \n        num_images = z_end - z_start + 1\n        self.images = np.empty(\n            (\n                num_images,\n                self.mask.shape[0] + self._left_pad_image + self._right_pad_image,\n                self.mask.shape[1] + self._top_pad_image + self._bottom_pad_image\n            ), \n            dtype=np.float32\n        )\n        for index, i in enumerate(range(z_start, z_end)):\n            # noinspection PyTypeChecker\n            image = np.array(Image.open(f\"{self.dir_path}\"\n                                        f\"/{self._relative_sv_dir}\"\n                                        f\"/{self.z_start + i:02d}.tif\"),\n                             dtype=np.float32) / 65535.0\n            image = np.pad(image, ((self._left_pad_mask + self._left_pad_image,\n                                    self._right_pad_mask + self._right_pad_image),\n                                   (self._top_pad_mask + self._top_pad_image,\n                                    self._bottom_pad_mask + self._bottom_pad_image)),\n                           'constant', constant_values=0)\n            self.images[index, :, :] = image\n            \n    def _load_scale(self):\n        current_stack_layer = self.z_start\n        images = np.empty(\n            (\n                len(self.compress_depth),\n                self.mask.shape[0] + self._left_pad_image + self._right_pad_image,\n                self.mask.shape[1] + self._top_pad_image + self._bottom_pad_image\n            ), \n            dtype=np.float32\n        )\n        for index,layer in enumerate(self.compress_depth):\n            self._load_images(current_stack_layer, current_stack_layer + layer)\n            current_stack_layer += layer + 1\n            layer_stack = self.images\n            images[index,:,:] = np.mean(layer_stack,axis = 0)\n            \n        self.images = images\n    \n    # Internal utility methods\n    def _setup(self):\n        # noinspection PyTypeChecker\n        self.mask = np.array(Image.open(f\"{self.dir_path}/mask.png\"))\n        # noinspection PyTypeChecker\n        self.inklabels = np.array(Image.open(f\"{self.dir_path}/inklabels.png\"))\n        self._granulate_mask()\n        self._fill_new_mask()\n        if self.compress_depth is None:\n            self._load_images()\n        else:\n            self._load_scale()\n        self._get_leftover_hull()\n\n    def _granulate_mask(self):\n        self._get_paddings()\n        self.mask = np.pad(self.mask,\n                           ((self._left_pad_mask, self._right_pad_mask),\n                            (self._top_pad_mask, self._bottom_pad_mask)),\n                           'constant', constant_values=0)\n        self.indices = _find_labeled_nucleus(self.mask, self.nucleus_shape)\n        self.inklabels = np.pad(self.inklabels, \n                                ((self._left_pad_mask, self._right_pad_mask),\n                                 (self._top_pad_mask, self._bottom_pad_mask)),\n                                'constant', \n                                constant_values=0)\n\n    def _get_paddings(self):\n        width, height = self.mask.shape\n        nucleus_width, nucleus_height = self.nucleus_shape\n        hull_width, hull_height = self.hull_size\n        self._left_pad_mask = (width % nucleus_width) // 2\n        self._right_pad_mask = width % nucleus_width - self._left_pad_mask\n        self._top_pad_mask = (height % nucleus_height) // 2\n        self._bottom_pad_mask = height % nucleus_height - self._top_pad_mask\n\n        self._left_pad_image = (hull_width - nucleus_width) // 2\n        self._right_pad_image = hull_width - nucleus_width - self._left_pad_image\n        self._top_pad_image = (hull_height - nucleus_height) // 2\n        self._bottom_pad_image = hull_height - nucleus_height - self._top_pad_image\n\n    def _fill_new_mask(self):\n        nucleus_width, nucleus_height = self.nucleus_shape\n        self.mask = np.zeros_like(self.mask)\n        for index in self.indices:\n            i, j = self._get_pixel_from_index(index)\n            self.mask[\n                i * nucleus_width: (i + 1) * nucleus_width,\n                j * nucleus_height: (j + 1) * nucleus_height\n            ] = 1\n\n    def _get_pixel_from_index(self, index: int):\n        mask_width, mask_height = self.mask.shape\n        nucleus_width, nucleus_height = self.nucleus_shape\n        height = mask_height // nucleus_height\n        return index // height * nucleus_height, index % height * nucleus_width\n\n    def _get_leftover_hull(self):\n        nucleus_width, nucleus_height = self.nucleus_shape\n        hull_width, hull_height = self.hull_size\n        self._left_hull = (hull_width - nucleus_width) // 2\n        self._right_hull = hull_width - nucleus_width - self._left_hull\n        self._top_hull = (hull_height - nucleus_height) // 2\n        self._bottom_hull = hull_height - nucleus_height - self._top_hull\n\n\n@numba.njit()\ndef _find_labeled_nucleus(mask, nuclues_shape):\n    width, height = mask.shape\n    nucleus_width, nucleus_height = nuclues_shape\n\n    indices = - np.ones((width // nucleus_width) * (height // nucleus_height), dtype=np.int32)\n    current_index = 0\n    for i in range(width // nucleus_width):\n        for j in range(height // nucleus_height):\n            if np.sum(\n                    mask[i * nucleus_width: (i + 1) * nucleus_width,\n                         j * nucleus_height: (j + 1) * nucleus_height]\n                      ) > 0:\n                indices[current_index] = i * (height // nucleus_height) + j\n                current_index += 1\n    return indices[indices != -1]\n","metadata":{"execution":{"iopub.status.busy":"2023-05-28T21:28:21.800470Z","iopub.execute_input":"2023-05-28T21:28:21.800900Z","iopub.status.idle":"2023-05-28T21:28:21.833787Z","shell.execute_reply.started":"2023-05-28T21:28:21.800866Z","shell.execute_reply":"2023-05-28T21:28:21.832164Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"data1 = VesuviusTrainData(\n    dir_path=\"/kaggle/input/vesuvius-challenge-ink-detection/train/1\"\\\n    ,nucleus_shape = (12,12),hull_size=(32,32), z_start=0\\\n    , z_end=60,compress_depth=[20,20,20],give_indx=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T21:38:19.998360Z","iopub.execute_input":"2023-05-28T21:38:19.998789Z","iopub.status.idle":"2023-05-28T21:38:37.026686Z","shell.execute_reply.started":"2023-05-28T21:38:19.998742Z","shell.execute_reply":"2023-05-28T21:38:37.024895Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"data3 = VesuviusTrainData(\n    dir_path=\"/kaggle/input/vesuvius-challenge-ink-detection/train/3\"\\\n    ,nucleus_shape = (12,12),hull_size=(32,32), z_start=0\\\n    , z_end=60,compress_depth=[20,20,20],give_indx=True,istransform = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import ConcatDataset\nmerged_dataset = ConcatDataset([data1, data3])","metadata":{"execution":{"iopub.status.busy":"2023-05-28T22:20:40.764473Z","iopub.execute_input":"2023-05-28T22:20:40.764908Z","iopub.status.idle":"2023-05-28T22:20:40.772130Z","shell.execute_reply.started":"2023-05-28T22:20:40.764877Z","shell.execute_reply":"2023-05-28T22:20:40.769752Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\n\nclass Autoencoder(nn.Module):\n    def __init__(self):\n        super(Autoencoder, self).__init__()\n        \n        # Encoder layers\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(16, 8, kernel_size=3, stride=2, padding=1),\n            nn.ReLU()\n        )\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(8, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(16, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n            nn.ReLU()\n        )\n        \n        self.loss_list = []\n    \n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n    \n    def augment(self,dataset):\n        augmentation = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.ColorJitter(),\n        transforms.ToTensor()\n        ])\n\n        augmented_data = []\n        for image in dataset:\n            augmented_image = augmentation(image)\n            augmented_data.append(augmented_image)\n\n        return torch.stack(augmented_data)\n    \n    \n    def fit(self,data,criterion,optimizer,batch_size=1024, num_epochs=20,verbose = False):\n        dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n        for epoch in range(num_epochs):\n            epoch_loss = []\n            for batch_idx, (data, target, indxs) in tqdm(enumerate(dataloader)):\n                inputs = self.augment(data)\n                outputs = autoencoder(inputs)\n                loss = criterion(outputs, inputs)\n                result = np.sum(np.abs(self.forward(data).detach().numpy()-data.numpy()))\n                epoch_loss.append(result)\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n                if batch_idx == 20:\n                    break\n                \n            self.loss_list.append(np.mean(epoch_loss))\n            if verbose == True:    \n                print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {self.loss_list[-1]:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-28T22:59:03.024558Z","iopub.execute_input":"2023-05-28T22:59:03.025069Z","iopub.status.idle":"2023-05-28T22:59:03.040541Z","shell.execute_reply.started":"2023-05-28T22:59:03.025023Z","shell.execute_reply":"2023-05-28T22:59:03.039546Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"autoencoder = Autoencoder()\n#autoencoder.load_state_dict(torch.load('/kaggle/input/auto-encoder-weight/autoencoder_weights.pth'\\\n#                                 , map_location=torch.device('cpu')))\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(autoencoder.parameters(), lr=0.005)\nnum_epochs=10\nautoencoder.fit(merged_dataset,criterion=criterion,optimizer=optimizer,num_epochs=num_epochs\\\n                ,verbose =True)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T23:00:26.288930Z","iopub.execute_input":"2023-05-28T23:00:26.289380Z","iopub.status.idle":"2023-05-28T23:02:31.114832Z","shell.execute_reply.started":"2023-05-28T23:00:26.289346Z","shell.execute_reply":"2023-05-28T23:02:31.113000Z"},"trusted":true},"execution_count":92,"outputs":[{"name":"stderr","text":"20it [00:12,  1.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/10], Loss: 686952.0625\n","output_type":"stream"},{"name":"stderr","text":"20it [00:12,  1.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/10], Loss: 405766.6562\n","output_type":"stream"},{"name":"stderr","text":"20it [00:12,  1.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3/10], Loss: 286760.4688\n","output_type":"stream"},{"name":"stderr","text":"20it [00:13,  1.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4/10], Loss: 211429.7812\n","output_type":"stream"},{"name":"stderr","text":"20it [00:12,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5/10], Loss: 131932.8750\n","output_type":"stream"},{"name":"stderr","text":"20it [00:12,  1.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [6/10], Loss: 109890.2969\n","output_type":"stream"},{"name":"stderr","text":"20it [00:12,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [7/10], Loss: 106929.4297\n","output_type":"stream"},{"name":"stderr","text":"20it [00:12,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [8/10], Loss: 100020.9609\n","output_type":"stream"},{"name":"stderr","text":"20it [00:12,  1.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [9/10], Loss: 97181.9609\n","output_type":"stream"},{"name":"stderr","text":"20it [00:12,  1.64it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [10/10], Loss: 95427.6875\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"autoencoder.encoder(data1[0][0]).shape","metadata":{"execution":{"iopub.status.busy":"2023-05-28T23:02:34.229115Z","iopub.execute_input":"2023-05-28T23:02:34.229582Z","iopub.status.idle":"2023-05-28T23:02:34.238465Z","shell.execute_reply.started":"2023-05-28T23:02:34.229547Z","shell.execute_reply":"2023-05-28T23:02:34.237488Z"},"trusted":true},"execution_count":93,"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"torch.Size([10, 8, 8])"},"metadata":{}}]},{"cell_type":"code","source":"num_epochs=10\nautoencoder.fit(merged_dataset,criterion=criterion,optimizer=optimizer,num_epochs=num_epochs\\\n                ,verbose =True)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T23:18:40.935851Z","iopub.execute_input":"2023-05-28T23:18:40.936427Z","iopub.status.idle":"2023-05-28T23:20:42.237582Z","shell.execute_reply.started":"2023-05-28T23:18:40.936370Z","shell.execute_reply":"2023-05-28T23:20:42.235852Z"},"trusted":true},"execution_count":103,"outputs":[{"name":"stderr","text":"20it [00:12,  1.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/10], Loss: 34905.5195\n","output_type":"stream"},{"name":"stderr","text":"20it [00:12,  1.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/10], Loss: 33654.4688\n","output_type":"stream"},{"name":"stderr","text":"20it [00:12,  1.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3/10], Loss: 33438.1172\n","output_type":"stream"},{"name":"stderr","text":"20it [00:11,  1.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4/10], Loss: 33170.9180\n","output_type":"stream"},{"name":"stderr","text":"20it [00:12,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5/10], Loss: 34437.7422\n","output_type":"stream"},{"name":"stderr","text":"20it [00:12,  1.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [6/10], Loss: 35078.1445\n","output_type":"stream"},{"name":"stderr","text":"20it [00:12,  1.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [7/10], Loss: 32606.7734\n","output_type":"stream"},{"name":"stderr","text":"20it [00:12,  1.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [8/10], Loss: 32581.2715\n","output_type":"stream"},{"name":"stderr","text":"20it [00:12,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [9/10], Loss: 32213.3242\n","output_type":"stream"},{"name":"stderr","text":"20it [00:12,  1.64it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [10/10], Loss: 37251.1953\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(autoencoder.state_dict(), 'autoencoder_weights.pth')","metadata":{"execution":{"iopub.status.busy":"2023-05-28T22:18:08.496701Z","iopub.execute_input":"2023-05-28T22:18:08.497180Z","iopub.status.idle":"2023-05-28T22:18:08.509025Z","shell.execute_reply.started":"2023-05-28T22:18:08.497151Z","shell.execute_reply":"2023-05-28T22:18:08.507836Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"data2 = VesuviusTrainData(\n    dir_path=\"/kaggle/input/vesuvius-challenge-ink-detection/train/2\"\\\n    ,nucleus_shape = (12,12),hull_size=(32,32), z_start=0\\\n    , z_end=60,compress_depth=[20,20,20],give_indx=True,istransform = False)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T22:04:34.112970Z","iopub.execute_input":"2023-05-28T22:04:34.113389Z","iopub.status.idle":"2023-05-28T22:10:31.143958Z","shell.execute_reply.started":"2023-05-28T22:04:34.113358Z","shell.execute_reply":"2023-05-28T22:10:31.141952Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/PIL/Image.py:3176: DecompressionBombWarning: Image size (140973980 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"loader = DataLoader(data2, batch_size=1024, shuffle=True)\n\nresult_loss = []\nfor batch_idx, (data, target, indices) in enumerate(loader): \n    result_loss.append(np.sum(np.abs(autoencoder(data).detach().numpy()-data.numpy())))\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-05-28T23:21:59.789031Z","iopub.execute_input":"2023-05-28T23:21:59.789478Z","iopub.status.idle":"2023-05-28T23:23:18.343148Z","shell.execute_reply.started":"2023-05-28T23:21:59.789444Z","shell.execute_reply":"2023-05-28T23:23:18.341553Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"print(np.mean(result_loss))","metadata":{"execution":{"iopub.status.busy":"2023-05-28T23:23:18.345478Z","iopub.execute_input":"2023-05-28T23:23:18.345913Z","iopub.status.idle":"2023-05-28T23:23:18.353513Z","shell.execute_reply.started":"2023-05-28T23:23:18.345872Z","shell.execute_reply":"2023-05-28T23:23:18.351941Z"},"trusted":true},"execution_count":105,"outputs":[{"name":"stdout","text":"37647.38\n","output_type":"stream"}]},{"cell_type":"code","source":"print((12*12*1024-33604.33)/(12*12*1024))","metadata":{"execution":{"iopub.status.busy":"2023-05-28T22:45:18.007233Z","iopub.execute_input":"2023-05-28T22:45:18.007645Z","iopub.status.idle":"2023-05-28T22:45:18.014836Z","shell.execute_reply.started":"2023-05-28T22:45:18.007616Z","shell.execute_reply":"2023-05-28T22:45:18.012582Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"0.7721060519748264\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}